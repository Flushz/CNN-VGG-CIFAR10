{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14cae0d",
   "metadata": {
    "papermill": {
     "duration": 0.009945,
     "end_time": "2021-12-16T11:20:54.714975",
     "exception": false,
     "start_time": "2021-12-16T11:20:54.705030",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c2142d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-16T11:20:54.744570Z",
     "iopub.status.busy": "2021-12-16T11:20:54.743787Z",
     "iopub.status.idle": "2021-12-16T11:20:59.641653Z",
     "shell.execute_reply": "2021-12-16T11:20:59.640703Z",
     "shell.execute_reply.started": "2021-12-16T11:19:50.334911Z"
    },
    "papermill": {
     "duration": 4.915811,
     "end_time": "2021-12-16T11:20:59.641810",
     "exception": false,
     "start_time": "2021-12-16T11:20:54.725999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea910798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-16T11:20:59.658587Z",
     "iopub.status.busy": "2021-12-16T11:20:59.657014Z",
     "iopub.status.idle": "2021-12-16T11:20:59.659167Z",
     "shell.execute_reply": "2021-12-16T11:20:59.659599Z",
     "shell.execute_reply.started": "2021-12-16T11:19:56.113835Z"
    },
    "papermill": {
     "duration": 0.012145,
     "end_time": "2021-12-16T11:20:59.659722",
     "exception": false,
     "start_time": "2021-12-16T11:20:59.647577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d12dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-16T11:20:59.675150Z",
     "iopub.status.busy": "2021-12-16T11:20:59.674429Z",
     "iopub.status.idle": "2021-12-16T11:20:59.676800Z",
     "shell.execute_reply": "2021-12-16T11:20:59.676386Z",
     "shell.execute_reply.started": "2021-12-16T11:19:56.123914Z"
    },
    "papermill": {
     "duration": 0.011734,
     "end_time": "2021-12-16T11:20:59.676904",
     "exception": false,
     "start_time": "2021-12-16T11:20:59.665170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d187cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-16T11:20:59.705352Z",
     "iopub.status.busy": "2021-12-16T11:20:59.694858Z",
     "iopub.status.idle": "2021-12-16T11:20:59.707528Z",
     "shell.execute_reply": "2021-12-16T11:20:59.707086Z",
     "shell.execute_reply.started": "2021-12-16T11:19:56.138648Z"
    },
    "papermill": {
     "duration": 0.025392,
     "end_time": "2021-12-16T11:20:59.707629",
     "exception": false,
     "start_time": "2021-12-16T11:20:59.682237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.45))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3e563c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-16T11:20:59.725372Z",
     "iopub.status.busy": "2021-12-16T11:20:59.724606Z",
     "iopub.status.idle": "2021-12-16T11:20:59.726509Z",
     "shell.execute_reply": "2021-12-16T11:20:59.726868Z",
     "shell.execute_reply.started": "2021-12-16T11:19:56.159280Z"
    },
    "papermill": {
     "duration": 0.013989,
     "end_time": "2021-12-16T11:20:59.726992",
     "exception": false,
     "start_time": "2021-12-16T11:20:59.713003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    \n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    \n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8cfe87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-16T11:20:59.740636Z",
     "iopub.status.busy": "2021-12-16T11:20:59.739843Z",
     "iopub.status.idle": "2021-12-16T13:35:05.626214Z",
     "shell.execute_reply": "2021-12-16T13:35:05.625744Z"
    },
    "papermill": {
     "duration": 8045.894008,
     "end_time": "2021-12-16T13:35:05.626370",
     "exception": false,
     "start_time": "2021-12-16T11:20:59.732362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 3s 0us/step\n",
      "170508288/170498071 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 11:21:04.961635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 11:21:05.057027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 11:21:05.057739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 11:21:05.059396: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-16 11:21:05.060794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 11:21:05.061730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 11:21:05.062659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 11:21:06.906738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 11:21:06.907647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 11:21:06.908303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-16 11:21:06.908885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2021-12-16 11:21:07.844120: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 11:21:10.387080: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 43s 45ms/step - loss: 2.5657 - accuracy: 0.1942 - val_loss: 1.8065 - val_accuracy: 0.3201\n",
      "Epoch 2/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 1.8752 - accuracy: 0.2998 - val_loss: 1.6345 - val_accuracy: 0.3852\n",
      "Epoch 3/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 1.6792 - accuracy: 0.3664 - val_loss: 1.5161 - val_accuracy: 0.4339\n",
      "Epoch 4/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 1.5803 - accuracy: 0.4050 - val_loss: 1.4514 - val_accuracy: 0.4625\n",
      "Epoch 5/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 1.4864 - accuracy: 0.4453 - val_loss: 1.6197 - val_accuracy: 0.4567\n",
      "Epoch 6/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 1.4009 - accuracy: 0.4821 - val_loss: 1.3883 - val_accuracy: 0.5160\n",
      "Epoch 7/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 1.3413 - accuracy: 0.5083 - val_loss: 1.2765 - val_accuracy: 0.5502\n",
      "Epoch 8/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 1.2794 - accuracy: 0.5345 - val_loss: 1.3824 - val_accuracy: 0.5213\n",
      "Epoch 9/200\n",
      "781/781 [==============================] - 35s 44ms/step - loss: 1.2346 - accuracy: 0.5531 - val_loss: 1.2597 - val_accuracy: 0.5698\n",
      "Epoch 10/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 1.1796 - accuracy: 0.5752 - val_loss: 1.3192 - val_accuracy: 0.5691\n",
      "Epoch 11/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 1.1384 - accuracy: 0.5955 - val_loss: 1.1724 - val_accuracy: 0.6021\n",
      "Epoch 12/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 1.1005 - accuracy: 0.6098 - val_loss: 1.1018 - val_accuracy: 0.6187\n",
      "Epoch 13/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 1.0660 - accuracy: 0.6207 - val_loss: 1.0622 - val_accuracy: 0.6276\n",
      "Epoch 14/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 1.0286 - accuracy: 0.6383 - val_loss: 1.1222 - val_accuracy: 0.6224\n",
      "Epoch 15/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.9917 - accuracy: 0.6521 - val_loss: 0.9876 - val_accuracy: 0.6600\n",
      "Epoch 16/200\n",
      "781/781 [==============================] - 35s 44ms/step - loss: 0.9648 - accuracy: 0.6595 - val_loss: 1.2394 - val_accuracy: 0.6149\n",
      "Epoch 17/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.9374 - accuracy: 0.6728 - val_loss: 0.9523 - val_accuracy: 0.6713\n",
      "Epoch 18/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.9071 - accuracy: 0.6833 - val_loss: 0.9573 - val_accuracy: 0.6779\n",
      "Epoch 19/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.8848 - accuracy: 0.6916 - val_loss: 0.9000 - val_accuracy: 0.6866\n",
      "Epoch 20/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.8636 - accuracy: 0.7000 - val_loss: 0.8971 - val_accuracy: 0.7043\n",
      "Epoch 21/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.8411 - accuracy: 0.7082 - val_loss: 0.8365 - val_accuracy: 0.7178\n",
      "Epoch 22/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.8192 - accuracy: 0.7165 - val_loss: 0.8258 - val_accuracy: 0.7274\n",
      "Epoch 23/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.8070 - accuracy: 0.7227 - val_loss: 0.8359 - val_accuracy: 0.7251\n",
      "Epoch 24/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.7911 - accuracy: 0.7282 - val_loss: 0.7532 - val_accuracy: 0.7461\n",
      "Epoch 25/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.7687 - accuracy: 0.7374 - val_loss: 0.7800 - val_accuracy: 0.7392\n",
      "Epoch 26/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.7541 - accuracy: 0.7405 - val_loss: 0.7525 - val_accuracy: 0.7495\n",
      "Epoch 27/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.7450 - accuracy: 0.7444 - val_loss: 0.7833 - val_accuracy: 0.7407\n",
      "Epoch 28/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.7259 - accuracy: 0.7499 - val_loss: 1.0151 - val_accuracy: 0.6809\n",
      "Epoch 29/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.7130 - accuracy: 0.7563 - val_loss: 0.7682 - val_accuracy: 0.7460\n",
      "Epoch 30/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.7014 - accuracy: 0.7610 - val_loss: 0.6837 - val_accuracy: 0.7723\n",
      "Epoch 31/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.6812 - accuracy: 0.7691 - val_loss: 0.6632 - val_accuracy: 0.7793\n",
      "Epoch 32/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.6695 - accuracy: 0.7723 - val_loss: 0.7881 - val_accuracy: 0.7488\n",
      "Epoch 33/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.6628 - accuracy: 0.7758 - val_loss: 0.6756 - val_accuracy: 0.7771\n",
      "Epoch 34/200\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6505 - accuracy: 0.7806 - val_loss: 0.7296 - val_accuracy: 0.7597\n",
      "Epoch 35/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.6332 - accuracy: 0.7871 - val_loss: 0.5759 - val_accuracy: 0.8066\n",
      "Epoch 36/200\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.6295 - accuracy: 0.7877 - val_loss: 0.6424 - val_accuracy: 0.7904\n",
      "Epoch 37/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.6244 - accuracy: 0.7896 - val_loss: 0.5982 - val_accuracy: 0.8012\n",
      "Epoch 38/200\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.6181 - accuracy: 0.7923 - val_loss: 0.6460 - val_accuracy: 0.7918\n",
      "Epoch 39/200\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.6029 - accuracy: 0.7973 - val_loss: 0.6421 - val_accuracy: 0.7916\n",
      "Epoch 40/200\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.5867 - accuracy: 0.8022 - val_loss: 0.6266 - val_accuracy: 0.7946\n",
      "Epoch 41/200\n",
      "781/781 [==============================] - 35s 44ms/step - loss: 0.5843 - accuracy: 0.8042 - val_loss: 0.5977 - val_accuracy: 0.8048\n",
      "Epoch 42/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.5723 - accuracy: 0.8069 - val_loss: 0.5381 - val_accuracy: 0.8211\n",
      "Epoch 43/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.5617 - accuracy: 0.8123 - val_loss: 0.5738 - val_accuracy: 0.8143\n",
      "Epoch 44/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.5552 - accuracy: 0.8149 - val_loss: 0.5689 - val_accuracy: 0.8089\n",
      "Epoch 45/200\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5574 - accuracy: 0.8118 - val_loss: 0.6085 - val_accuracy: 0.8059\n",
      "Epoch 46/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.5460 - accuracy: 0.8178 - val_loss: 0.5516 - val_accuracy: 0.8222\n",
      "Epoch 47/200\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5303 - accuracy: 0.8226 - val_loss: 0.5722 - val_accuracy: 0.8144\n",
      "Epoch 48/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.5253 - accuracy: 0.8232 - val_loss: 0.5446 - val_accuracy: 0.8214\n",
      "Epoch 49/200\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5205 - accuracy: 0.8260 - val_loss: 0.5727 - val_accuracy: 0.8157\n",
      "Epoch 50/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.5175 - accuracy: 0.8268 - val_loss: 0.5470 - val_accuracy: 0.8184\n",
      "Epoch 51/200\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.5079 - accuracy: 0.8279 - val_loss: 0.5559 - val_accuracy: 0.8178\n",
      "Epoch 52/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.5030 - accuracy: 0.8310 - val_loss: 0.4959 - val_accuracy: 0.8327\n",
      "Epoch 53/200\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4946 - accuracy: 0.8339 - val_loss: 0.6172 - val_accuracy: 0.8012\n",
      "Epoch 54/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.4880 - accuracy: 0.8355 - val_loss: 0.5746 - val_accuracy: 0.8138\n",
      "Epoch 55/200\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.4868 - accuracy: 0.8376 - val_loss: 0.5190 - val_accuracy: 0.8313\n",
      "Epoch 56/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4785 - accuracy: 0.8398 - val_loss: 0.5107 - val_accuracy: 0.8340\n",
      "Epoch 57/200\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.4678 - accuracy: 0.8421 - val_loss: 0.4958 - val_accuracy: 0.8346\n",
      "Epoch 58/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4702 - accuracy: 0.8418 - val_loss: 0.4838 - val_accuracy: 0.8440\n",
      "Epoch 59/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4662 - accuracy: 0.8426 - val_loss: 0.4874 - val_accuracy: 0.8433\n",
      "Epoch 60/200\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4542 - accuracy: 0.8463 - val_loss: 0.4809 - val_accuracy: 0.8450\n",
      "Epoch 61/200\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.4465 - accuracy: 0.8504 - val_loss: 0.5513 - val_accuracy: 0.8240\n",
      "Epoch 62/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4423 - accuracy: 0.8525 - val_loss: 0.4605 - val_accuracy: 0.8504\n",
      "Epoch 63/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4410 - accuracy: 0.8497 - val_loss: 0.5608 - val_accuracy: 0.8203\n",
      "Epoch 64/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4322 - accuracy: 0.8538 - val_loss: 0.4695 - val_accuracy: 0.8466\n",
      "Epoch 65/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.4283 - accuracy: 0.8559 - val_loss: 0.5115 - val_accuracy: 0.8363\n",
      "Epoch 66/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4288 - accuracy: 0.8575 - val_loss: 0.4359 - val_accuracy: 0.8556\n",
      "Epoch 67/200\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.4147 - accuracy: 0.8614 - val_loss: 0.5081 - val_accuracy: 0.8386\n",
      "Epoch 68/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.4112 - accuracy: 0.8623 - val_loss: 0.4826 - val_accuracy: 0.8496\n",
      "Epoch 69/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.4113 - accuracy: 0.8611 - val_loss: 0.4445 - val_accuracy: 0.8547\n",
      "Epoch 70/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.4091 - accuracy: 0.8634 - val_loss: 0.4753 - val_accuracy: 0.8476\n",
      "Epoch 71/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.4002 - accuracy: 0.8654 - val_loss: 0.4431 - val_accuracy: 0.8582\n",
      "Epoch 72/200\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.3963 - accuracy: 0.8689 - val_loss: 0.5119 - val_accuracy: 0.8347\n",
      "Epoch 73/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3912 - accuracy: 0.8688 - val_loss: 0.4230 - val_accuracy: 0.8646\n",
      "Epoch 74/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.3901 - accuracy: 0.8691 - val_loss: 0.4316 - val_accuracy: 0.8601\n",
      "Epoch 75/200\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3819 - accuracy: 0.8738 - val_loss: 0.4344 - val_accuracy: 0.8606\n",
      "Epoch 76/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.3809 - accuracy: 0.8732 - val_loss: 0.4345 - val_accuracy: 0.8629\n",
      "Epoch 77/200\n",
      "781/781 [==============================] - 32s 42ms/step - loss: 0.3770 - accuracy: 0.8731 - val_loss: 0.4539 - val_accuracy: 0.8552\n",
      "Epoch 78/200\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3698 - accuracy: 0.8760 - val_loss: 0.4051 - val_accuracy: 0.8726\n",
      "Epoch 79/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3678 - accuracy: 0.8763 - val_loss: 0.4461 - val_accuracy: 0.8572\n",
      "Epoch 80/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3632 - accuracy: 0.8797 - val_loss: 0.4463 - val_accuracy: 0.8579\n",
      "Epoch 81/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.3606 - accuracy: 0.8784 - val_loss: 0.4411 - val_accuracy: 0.8581\n",
      "Epoch 82/200\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3584 - accuracy: 0.8803 - val_loss: 0.4516 - val_accuracy: 0.8580\n",
      "Epoch 83/200\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.3469 - accuracy: 0.8844 - val_loss: 0.4175 - val_accuracy: 0.8689\n",
      "Epoch 84/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3506 - accuracy: 0.8828 - val_loss: 0.4142 - val_accuracy: 0.8684\n",
      "Epoch 85/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.3506 - accuracy: 0.8828 - val_loss: 0.4012 - val_accuracy: 0.8720\n",
      "Epoch 86/200\n",
      "781/781 [==============================] - 35s 44ms/step - loss: 0.3407 - accuracy: 0.8862 - val_loss: 0.4144 - val_accuracy: 0.8698\n",
      "Epoch 87/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.3441 - accuracy: 0.8838 - val_loss: 0.4092 - val_accuracy: 0.8727\n",
      "Epoch 88/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3376 - accuracy: 0.8857 - val_loss: 0.4413 - val_accuracy: 0.8618\n",
      "Epoch 89/200\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.3319 - accuracy: 0.8876 - val_loss: 0.4762 - val_accuracy: 0.8518\n",
      "Epoch 90/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3355 - accuracy: 0.8877 - val_loss: 0.4351 - val_accuracy: 0.8634\n",
      "Epoch 91/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3301 - accuracy: 0.8888 - val_loss: 0.3970 - val_accuracy: 0.8731\n",
      "Epoch 92/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.3248 - accuracy: 0.8915 - val_loss: 0.4197 - val_accuracy: 0.8688\n",
      "Epoch 93/200\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3195 - accuracy: 0.8938 - val_loss: 0.4877 - val_accuracy: 0.8509\n",
      "Epoch 94/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3200 - accuracy: 0.8929 - val_loss: 0.4270 - val_accuracy: 0.8702\n",
      "Epoch 95/200\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.3160 - accuracy: 0.8946 - val_loss: 0.4085 - val_accuracy: 0.8740\n",
      "Epoch 96/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.3087 - accuracy: 0.8971 - val_loss: 0.3931 - val_accuracy: 0.8773\n",
      "Epoch 97/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3078 - accuracy: 0.8977 - val_loss: 0.4611 - val_accuracy: 0.8582\n",
      "Epoch 98/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.3103 - accuracy: 0.8948 - val_loss: 0.3981 - val_accuracy: 0.8750\n",
      "Epoch 99/200\n",
      "781/781 [==============================] - 43s 54ms/step - loss: 0.3016 - accuracy: 0.8983 - val_loss: 0.4076 - val_accuracy: 0.8741\n",
      "Epoch 100/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.2984 - accuracy: 0.9008 - val_loss: 0.4216 - val_accuracy: 0.8724\n",
      "Epoch 101/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.3004 - accuracy: 0.8999 - val_loss: 0.4339 - val_accuracy: 0.8652\n",
      "Epoch 102/200\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2910 - accuracy: 0.9012 - val_loss: 0.3973 - val_accuracy: 0.8757\n",
      "Epoch 103/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2894 - accuracy: 0.9027 - val_loss: 0.4616 - val_accuracy: 0.8627\n",
      "Epoch 104/200\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2895 - accuracy: 0.9032 - val_loss: 0.4119 - val_accuracy: 0.8717\n",
      "Epoch 105/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.2837 - accuracy: 0.9047 - val_loss: 0.4254 - val_accuracy: 0.8717\n",
      "Epoch 106/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2875 - accuracy: 0.9041 - val_loss: 0.3989 - val_accuracy: 0.8772\n",
      "Epoch 107/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.2846 - accuracy: 0.9042 - val_loss: 0.3975 - val_accuracy: 0.8768\n",
      "Epoch 108/200\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.2846 - accuracy: 0.9041 - val_loss: 0.4497 - val_accuracy: 0.8659\n",
      "Epoch 109/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.2719 - accuracy: 0.9092 - val_loss: 0.3739 - val_accuracy: 0.8850\n",
      "Epoch 110/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2726 - accuracy: 0.9099 - val_loss: 0.3854 - val_accuracy: 0.8799\n",
      "Epoch 111/200\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 0.2747 - accuracy: 0.9084 - val_loss: 0.4124 - val_accuracy: 0.8752\n",
      "Epoch 112/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.2694 - accuracy: 0.9088 - val_loss: 0.4393 - val_accuracy: 0.8678\n",
      "Epoch 113/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2653 - accuracy: 0.9105 - val_loss: 0.4452 - val_accuracy: 0.8659\n",
      "Epoch 114/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2682 - accuracy: 0.9110 - val_loss: 0.3850 - val_accuracy: 0.8817\n",
      "Epoch 115/200\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.2591 - accuracy: 0.9123 - val_loss: 0.3772 - val_accuracy: 0.8828\n",
      "Epoch 116/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2582 - accuracy: 0.9133 - val_loss: 0.4039 - val_accuracy: 0.8787\n",
      "Epoch 117/200\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.2596 - accuracy: 0.9135 - val_loss: 0.3878 - val_accuracy: 0.8802\n",
      "Epoch 118/200\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2532 - accuracy: 0.9152 - val_loss: 0.4019 - val_accuracy: 0.8786\n",
      "Epoch 119/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2537 - accuracy: 0.9154 - val_loss: 0.3970 - val_accuracy: 0.8760\n",
      "Epoch 120/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.2503 - accuracy: 0.9155 - val_loss: 0.3989 - val_accuracy: 0.8822\n",
      "Epoch 121/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2538 - accuracy: 0.9139 - val_loss: 0.3709 - val_accuracy: 0.8865\n",
      "Epoch 122/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2468 - accuracy: 0.9181 - val_loss: 0.3917 - val_accuracy: 0.8788\n",
      "Epoch 123/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2355 - accuracy: 0.9207 - val_loss: 0.3958 - val_accuracy: 0.8820\n",
      "Epoch 124/200\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.2394 - accuracy: 0.9189 - val_loss: 0.4035 - val_accuracy: 0.8816\n",
      "Epoch 125/200\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2380 - accuracy: 0.9186 - val_loss: 0.3803 - val_accuracy: 0.8897\n",
      "Epoch 126/200\n",
      "781/781 [==============================] - 35s 44ms/step - loss: 0.2334 - accuracy: 0.9204 - val_loss: 0.3795 - val_accuracy: 0.8854\n",
      "Epoch 127/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2373 - accuracy: 0.9202 - val_loss: 0.3579 - val_accuracy: 0.8911\n",
      "Epoch 128/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2334 - accuracy: 0.9222 - val_loss: 0.3949 - val_accuracy: 0.8821\n",
      "Epoch 129/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.2274 - accuracy: 0.9239 - val_loss: 0.3989 - val_accuracy: 0.8802\n",
      "Epoch 130/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2261 - accuracy: 0.9241 - val_loss: 0.4230 - val_accuracy: 0.8766\n",
      "Epoch 131/200\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.2263 - accuracy: 0.9251 - val_loss: 0.3740 - val_accuracy: 0.8890\n",
      "Epoch 132/200\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.2228 - accuracy: 0.9247 - val_loss: 0.4004 - val_accuracy: 0.8827\n",
      "Epoch 133/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.2215 - accuracy: 0.9253 - val_loss: 0.3829 - val_accuracy: 0.8849\n",
      "Epoch 134/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.2269 - accuracy: 0.9239 - val_loss: 0.3824 - val_accuracy: 0.8860\n",
      "Epoch 135/200\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.2170 - accuracy: 0.9275 - val_loss: 0.3927 - val_accuracy: 0.8845\n",
      "Epoch 136/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2170 - accuracy: 0.9271 - val_loss: 0.3969 - val_accuracy: 0.8823\n",
      "Epoch 137/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.2172 - accuracy: 0.9281 - val_loss: 0.3888 - val_accuracy: 0.8874\n",
      "Epoch 138/200\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.2174 - accuracy: 0.9263 - val_loss: 0.3715 - val_accuracy: 0.8877\n",
      "Epoch 139/200\n",
      "781/781 [==============================] - 43s 54ms/step - loss: 0.2093 - accuracy: 0.9306 - val_loss: 0.3971 - val_accuracy: 0.8850\n",
      "Epoch 140/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.2075 - accuracy: 0.9318 - val_loss: 0.3997 - val_accuracy: 0.8828\n",
      "Epoch 141/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.2030 - accuracy: 0.9306 - val_loss: 0.3781 - val_accuracy: 0.8908\n",
      "Epoch 142/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.2046 - accuracy: 0.9308 - val_loss: 0.3893 - val_accuracy: 0.8851\n",
      "Epoch 143/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.2058 - accuracy: 0.9313 - val_loss: 0.3900 - val_accuracy: 0.8859\n",
      "Epoch 144/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.2013 - accuracy: 0.9325 - val_loss: 0.3961 - val_accuracy: 0.8842\n",
      "Epoch 145/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.2041 - accuracy: 0.9317 - val_loss: 0.3854 - val_accuracy: 0.8868\n",
      "Epoch 146/200\n",
      "781/781 [==============================] - 48s 61ms/step - loss: 0.1996 - accuracy: 0.9333 - val_loss: 0.3705 - val_accuracy: 0.8922\n",
      "Epoch 147/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.2006 - accuracy: 0.9324 - val_loss: 0.4064 - val_accuracy: 0.8813\n",
      "Epoch 148/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1960 - accuracy: 0.9325 - val_loss: 0.3880 - val_accuracy: 0.8891\n",
      "Epoch 149/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1942 - accuracy: 0.9345 - val_loss: 0.3987 - val_accuracy: 0.8868\n",
      "Epoch 150/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1885 - accuracy: 0.9367 - val_loss: 0.3724 - val_accuracy: 0.8934\n",
      "Epoch 151/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.1902 - accuracy: 0.9359 - val_loss: 0.4544 - val_accuracy: 0.8723\n",
      "Epoch 152/200\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.1901 - accuracy: 0.9365 - val_loss: 0.3814 - val_accuracy: 0.8918\n",
      "Epoch 153/200\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.1936 - accuracy: 0.9351 - val_loss: 0.3977 - val_accuracy: 0.8861\n",
      "Epoch 154/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.1877 - accuracy: 0.9366 - val_loss: 0.3626 - val_accuracy: 0.8961\n",
      "Epoch 155/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.1867 - accuracy: 0.9375 - val_loss: 0.3869 - val_accuracy: 0.8900\n",
      "Epoch 156/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.1801 - accuracy: 0.9389 - val_loss: 0.3890 - val_accuracy: 0.8910\n",
      "Epoch 157/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1791 - accuracy: 0.9399 - val_loss: 0.4064 - val_accuracy: 0.8866\n",
      "Epoch 158/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1810 - accuracy: 0.9391 - val_loss: 0.4512 - val_accuracy: 0.8746\n",
      "Epoch 159/200\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.1746 - accuracy: 0.9416 - val_loss: 0.3938 - val_accuracy: 0.8923\n",
      "Epoch 160/200\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1786 - accuracy: 0.9399 - val_loss: 0.3783 - val_accuracy: 0.8937\n",
      "Epoch 161/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.1775 - accuracy: 0.9407 - val_loss: 0.3723 - val_accuracy: 0.8952\n",
      "Epoch 162/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.1706 - accuracy: 0.9419 - val_loss: 0.4093 - val_accuracy: 0.8863\n",
      "Epoch 163/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1700 - accuracy: 0.9426 - val_loss: 0.3796 - val_accuracy: 0.8942\n",
      "Epoch 164/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1697 - accuracy: 0.9443 - val_loss: 0.3625 - val_accuracy: 0.8984\n",
      "Epoch 165/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1690 - accuracy: 0.9424 - val_loss: 0.3583 - val_accuracy: 0.9012\n",
      "Epoch 166/200\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.1668 - accuracy: 0.9431 - val_loss: 0.3918 - val_accuracy: 0.8909\n",
      "Epoch 167/200\n",
      "781/781 [==============================] - 47s 60ms/step - loss: 0.1685 - accuracy: 0.9433 - val_loss: 0.3734 - val_accuracy: 0.8969\n",
      "Epoch 168/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.1658 - accuracy: 0.9447 - val_loss: 0.3844 - val_accuracy: 0.8924\n",
      "Epoch 169/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1627 - accuracy: 0.9445 - val_loss: 0.3860 - val_accuracy: 0.8908\n",
      "Epoch 170/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1696 - accuracy: 0.9428 - val_loss: 0.3746 - val_accuracy: 0.8982\n",
      "Epoch 171/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1595 - accuracy: 0.9465 - val_loss: 0.3742 - val_accuracy: 0.9000\n",
      "Epoch 172/200\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.1611 - accuracy: 0.9463 - val_loss: 0.3721 - val_accuracy: 0.8985\n",
      "Epoch 173/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.1620 - accuracy: 0.9467 - val_loss: 0.3741 - val_accuracy: 0.8937\n",
      "Epoch 174/200\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.1566 - accuracy: 0.9478 - val_loss: 0.3634 - val_accuracy: 0.8991\n",
      "Epoch 175/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1558 - accuracy: 0.9478 - val_loss: 0.3824 - val_accuracy: 0.8932\n",
      "Epoch 176/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1587 - accuracy: 0.9458 - val_loss: 0.3711 - val_accuracy: 0.8988\n",
      "Epoch 177/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1542 - accuracy: 0.9479 - val_loss: 0.3871 - val_accuracy: 0.8966\n",
      "Epoch 178/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1568 - accuracy: 0.9468 - val_loss: 0.3874 - val_accuracy: 0.8965\n",
      "Epoch 179/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.1548 - accuracy: 0.9486 - val_loss: 0.3565 - val_accuracy: 0.9035\n",
      "Epoch 180/200\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.1507 - accuracy: 0.9491 - val_loss: 0.3717 - val_accuracy: 0.9004\n",
      "Epoch 181/200\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.1540 - accuracy: 0.9477 - val_loss: 0.4125 - val_accuracy: 0.8898\n",
      "Epoch 182/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1493 - accuracy: 0.9495 - val_loss: 0.4062 - val_accuracy: 0.8903\n",
      "Epoch 183/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1488 - accuracy: 0.9500 - val_loss: 0.3812 - val_accuracy: 0.8971\n",
      "Epoch 184/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.1477 - accuracy: 0.9510 - val_loss: 0.3753 - val_accuracy: 0.8959\n",
      "Epoch 185/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1474 - accuracy: 0.9500 - val_loss: 0.3820 - val_accuracy: 0.8964\n",
      "Epoch 186/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.1424 - accuracy: 0.9518 - val_loss: 0.3782 - val_accuracy: 0.9020\n",
      "Epoch 187/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1438 - accuracy: 0.9519 - val_loss: 0.4362 - val_accuracy: 0.8859\n",
      "Epoch 188/200\n",
      "781/781 [==============================] - 48s 62ms/step - loss: 0.1435 - accuracy: 0.9517 - val_loss: 0.3733 - val_accuracy: 0.9004\n",
      "Epoch 189/200\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.1408 - accuracy: 0.9530 - val_loss: 0.4112 - val_accuracy: 0.8910\n",
      "Epoch 190/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1395 - accuracy: 0.9529 - val_loss: 0.3597 - val_accuracy: 0.9048\n",
      "Epoch 191/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.1375 - accuracy: 0.9532 - val_loss: 0.3788 - val_accuracy: 0.8988\n",
      "Epoch 192/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1397 - accuracy: 0.9526 - val_loss: 0.3597 - val_accuracy: 0.9055\n",
      "Epoch 193/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1371 - accuracy: 0.9536 - val_loss: 0.4182 - val_accuracy: 0.8911\n",
      "Epoch 194/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.1389 - accuracy: 0.9534 - val_loss: 0.3733 - val_accuracy: 0.9002\n",
      "Epoch 195/200\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.1350 - accuracy: 0.9545 - val_loss: 0.4222 - val_accuracy: 0.8908\n",
      "Epoch 196/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1316 - accuracy: 0.9563 - val_loss: 0.4064 - val_accuracy: 0.8953\n",
      "Epoch 197/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1288 - accuracy: 0.9559 - val_loss: 0.3859 - val_accuracy: 0.9005\n",
      "Epoch 198/200\n",
      "781/781 [==============================] - 33s 42ms/step - loss: 0.1334 - accuracy: 0.9551 - val_loss: 0.3812 - val_accuracy: 0.8987\n",
      "Epoch 199/200\n",
      "781/781 [==============================] - 33s 43ms/step - loss: 0.1355 - accuracy: 0.9539 - val_loss: 0.3687 - val_accuracy: 0.9009\n",
      "Epoch 200/200\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.1279 - accuracy: 0.9567 - val_loss: 0.3883 - val_accuracy: 0.8973\n",
      "> 89.730\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    \n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    \n",
    "    model = define_model()\n",
    "    \n",
    "    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "    \n",
    "    it_train = datagen.flow(trainX, trainY, batch_size=64)\n",
    "    \n",
    "    steps = int(trainX.shape[0] / 64)\n",
    "    history = model.fit(it_train, steps_per_epoch=steps, epochs=200, validation_data=(testX, testY), verbose=1)\n",
    "    \n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "    summarize_diagnostics(history)\n",
    "    \n",
    "    model.save('./Thai_9_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8086.485713,
   "end_time": "2021-12-16T13:35:33.102369",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-16T11:20:46.616656",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
