{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# baseline model with dropout on the cifar10 dataset\nimport sys\nimport tensorflow as tf\nfrom matplotlib import pyplot\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.optimizers import SGD","metadata":{"execution":{"iopub.status.busy":"2021-12-16T03:26:09.658552Z","iopub.execute_input":"2021-12-16T03:26:09.658908Z","iopub.status.idle":"2021-12-16T03:26:11.434883Z","shell.execute_reply.started":"2021-12-16T03:26:09.658808Z","shell.execute_reply":"2021-12-16T03:26:11.434066Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# load train and test dataset\ndef load_dataset():\n    # load dataset\n    (trainX, trainY), (testX, testY) = cifar10.load_data()\n    # one hot encode target values\n    trainY = to_categorical(trainY)\n    testY = to_categorical(testY)\n    return trainX, trainY, testX, testY","metadata":{"execution":{"iopub.status.busy":"2021-12-16T03:26:11.439432Z","iopub.execute_input":"2021-12-16T03:26:11.441550Z","iopub.status.idle":"2021-12-16T03:26:11.448364Z","shell.execute_reply.started":"2021-12-16T03:26:11.439817Z","shell.execute_reply":"2021-12-16T03:26:11.447606Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# scale pixels\ndef prep_pixels(train, test):\n    # convert from integers to floats\n    train_norm = train.astype('float32')\n    test_norm = test.astype('float32')\n    # normalize to range 0-1\n    train_norm = train_norm / 255.0\n    test_norm = test_norm / 255.0\n    # return normalized images\n    return train_norm, test_norm","metadata":{"execution":{"iopub.status.busy":"2021-12-16T03:26:11.452423Z","iopub.execute_input":"2021-12-16T03:26:11.455076Z","iopub.status.idle":"2021-12-16T03:26:11.466389Z","shell.execute_reply.started":"2021-12-16T03:26:11.455026Z","shell.execute_reply":"2021-12-16T03:26:11.465548Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# plot diagnostic learning curves\ndef summarize_diagnostics(history):\n    # plot loss\n    pyplot.subplot(211)\n    pyplot.title('Cross Entropy Loss')\n    pyplot.plot(history.history['loss'], color='blue', label='train')\n    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n    # plot accuracy\n    pyplot.subplot(212)\n    pyplot.title('Classification Accuracy')\n    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n    # save plot to file\n    filename = sys.argv[0].split('/')[-1]\n    pyplot.savefig(filename + '_plot.png')\n    pyplot.close()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T03:26:11.471976Z","iopub.execute_input":"2021-12-16T03:26:11.472393Z","iopub.status.idle":"2021-12-16T03:26:11.484350Z","shell.execute_reply.started":"2021-12-16T03:26:11.472353Z","shell.execute_reply":"2021-12-16T03:26:11.483467Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# define cnn model\ndef define_model():\n    model = Sequential()\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    \n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    \n    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    \n    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    \n    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    \n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(4096, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(10, activation='softmax'))\n    # compile model\n    opt = SGD(learning_rate=0.001, momentum=0.9)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-16T03:26:11.489255Z","iopub.execute_input":"2021-12-16T03:26:11.491861Z","iopub.status.idle":"2021-12-16T03:26:11.512568Z","shell.execute_reply.started":"2021-12-16T03:26:11.491820Z","shell.execute_reply":"2021-12-16T03:26:11.511626Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    # load dataset\n    trainX, trainY, testX, testY = load_dataset()\n    \n    # prepare pixel data\n    trainX, testX = prep_pixels(trainX, testX)\n    \n    # define model\n    model = define_model()\n    \n    # fit model\n    history = model.fit(trainX, trainY, epochs=100, batch_size=64,\n                        validation_data=(testX, testY), verbose=1)\n    \n    # evaluate model\n    _, acc = model.evaluate(testX, testY, verbose=0)\n    print('> %.3f' % (acc * 100.0))\n    summarize_diagnostics(history)\n    \n    model.save('./final_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T03:26:11.513873Z","iopub.execute_input":"2021-12-16T03:26:11.514128Z","iopub.status.idle":"2021-12-16T04:01:41.280601Z","shell.execute_reply.started":"2021-12-16T03:26:11.514088Z","shell.execute_reply":"2021-12-16T04:01:41.279827Z"},"trusted":true},"execution_count":6,"outputs":[]}]}