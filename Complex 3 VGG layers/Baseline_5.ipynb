{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# baseline model with dropout on the cifar10 dataset\nimport sys\nimport tensorflow as tf\nfrom matplotlib import pyplot\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-15T13:27:10.954930Z","iopub.execute_input":"2021-12-15T13:27:10.955281Z","iopub.status.idle":"2021-12-15T13:27:10.962142Z","shell.execute_reply.started":"2021-12-15T13:27:10.955239Z","shell.execute_reply":"2021-12-15T13:27:10.961220Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# load train and test dataset\ndef load_dataset():\n    # load dataset\n    (trainX, trainY), (testX, testY) = cifar10.load_data()\n    # one hot encode target values\n    trainY = to_categorical(trainY)\n    testY = to_categorical(testY)\n    return trainX, trainY, testX, testY","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:27:10.963838Z","iopub.execute_input":"2021-12-15T13:27:10.964587Z","iopub.status.idle":"2021-12-15T13:27:10.975413Z","shell.execute_reply.started":"2021-12-15T13:27:10.964542Z","shell.execute_reply":"2021-12-15T13:27:10.974714Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# scale pixels\ndef prep_pixels(train, test):\n    # convert from integers to floats\n    train_norm = train.astype('float32')\n    test_norm = test.astype('float32')\n    # normalize to range 0-1\n    train_norm = train_norm / 255.0\n    test_norm = test_norm / 255.0\n    # return normalized images\n    return train_norm, test_norm","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:27:10.978476Z","iopub.execute_input":"2021-12-15T13:27:10.978787Z","iopub.status.idle":"2021-12-15T13:27:10.985648Z","shell.execute_reply.started":"2021-12-15T13:27:10.978759Z","shell.execute_reply":"2021-12-15T13:27:10.984946Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# define cnn model\ndef define_model():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.4))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation='softmax'))\n    # compile model\n    opt = SGD(learning_rate=0.001, momentum=0.9)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:27:10.988315Z","iopub.execute_input":"2021-12-15T13:27:10.989067Z","iopub.status.idle":"2021-12-15T13:27:11.001828Z","shell.execute_reply.started":"2021-12-15T13:27:10.989032Z","shell.execute_reply":"2021-12-15T13:27:11.001174Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# plot diagnostic learning curves\ndef summarize_diagnostics(history):\n    # plot loss\n    pyplot.subplot(211)\n    pyplot.title('Cross Entropy Loss')\n    pyplot.plot(history.history['loss'], color='blue', label='train')\n    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n    # plot accuracy\n    pyplot.subplot(212)\n    pyplot.title('Classification Accuracy')\n    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n    # save plot to file\n    filename = sys.argv[0].split('/')[-1]\n    pyplot.savefig(filename + '_plot.png')\n    pyplot.close()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:27:11.004191Z","iopub.execute_input":"2021-12-15T13:27:11.004394Z","iopub.status.idle":"2021-12-15T13:27:11.014787Z","shell.execute_reply.started":"2021-12-15T13:27:11.004364Z","shell.execute_reply":"2021-12-15T13:27:11.014100Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    # load dataset\n    trainX, trainY, testX, testY = load_dataset()\n    \n    # prepare pixel data\n    trainX, testX = prep_pixels(trainX, testX)\n    \n    # define model\n    model = define_model()\n    \n    # create data generator\n    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n    \n    # prepare iterator\n    it_train = datagen.flow(trainX, trainY, batch_size=64)\n    \n    # fit model\n    steps = int(trainX.shape[0] / 64)\n    history = model.fit(it_train, steps_per_epoch=steps, epochs=400, validation_data=(testX, testY), verbose=1)\n    \n    # evaluate model\n    _, acc = model.evaluate(testX, testY, verbose=0)\n    print('> %.3f' % (acc * 100.0))\n\n    # learning curves\n    summarize_diagnostics(history)\n    \n    model.save('./Minh_6_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:27:11.016298Z","iopub.execute_input":"2021-12-15T13:27:11.016671Z","iopub.status.idle":"2021-12-15T17:08:21.334864Z","shell.execute_reply.started":"2021-12-15T13:27:11.016541Z","shell.execute_reply":"2021-12-15T17:08:21.334162Z"},"trusted":true},"execution_count":42,"outputs":[]}]}